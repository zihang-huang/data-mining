{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c3d546",
   "metadata": {},
   "source": [
    "\n",
    "# Bank Marketing Campaign Classification\n",
    "\n",
    "Improved pipeline using one-hot encoding, stratified splits, and tuned gradient boosting to lift recall/F1 on the term deposit prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42effcd6",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ee09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import joblib\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2608781",
   "metadata": {},
   "source": [
    "## 2. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6cddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Resolve project paths and organize outputs\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if not (PROJECT_ROOT / \"datasets\").exists() and (PROJECT_ROOT.parent / \"datasets\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "if not (PROJECT_ROOT / \"datasets\").exists():\n",
    "    raise FileNotFoundError(\"Could not locate datasets folder. Run from project root or src directory.\")\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"datasets\" / \"bank-marketing\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n",
    "PLOTS_DIR = OUTPUT_DIR / \"plots\"\n",
    "MODELS_DIR = OUTPUT_DIR / \"models\"\n",
    "PREDICTIONS_DIR = OUTPUT_DIR / \"predictions\"\n",
    "for path in [OUTPUT_DIR, PLOTS_DIR, MODELS_DIR, PREDICTIONS_DIR]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Outputs directory: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d162f1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 45,211 rows and 17 columns\n",
      "y\n",
      "no     0.883015\n",
      "yes    0.116985\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = DATA_DIR / \"bank-full.csv\"\n",
    "df = pd.read_csv(data_path, sep=\";\")\n",
    "print(f\"Loaded {df.shape[0]:,} rows and {df.shape[1]} columns from {data_path}\")\n",
    "print(df[\"y\"].value_counts(normalize=True).rename(\"proportion\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea9b859",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Preprocessing\n",
    "\n",
    "- Remove extreme outliers on a few numeric fields.\n",
    "- Separate categorical vs numeric columns for proper encoding.\n",
    "- Stratified train/test split to preserve class balance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8366f905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After outlier filtering: 42,338 rows remain.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for col in [\"balance\", \"age\", \"duration\", \"campaign\"]:\n",
    "    z_scores = np.abs(df[col] - df[col].mean()) / df[col].std()\n",
    "    df = df[z_scores < 3]\n",
    "\n",
    "print(f\"After outlier filtering: {df.shape[0]:,} rows remain.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d223511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive class weight (train): 8.58\n",
      "Train size: 33870, Test size: 8468\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns=\"y\")\n",
    "y = df[\"y\"].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "categorical_cols = X.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "numeric_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "preprocess_template = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"categorical\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "        (\"numeric\", StandardScaler(with_mean=False), numeric_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "pos_weight = (len(y_train) - y_train.sum()) / y_train.sum()\n",
    "print(f\"Positive class weight (train): {pos_weight:.2f}\")\n",
    "print(f\"Train size: {X_train.shape[0]}, Test size: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5608ddff",
   "metadata": {},
   "source": [
    "# ？\n",
    "决策树设计了剪枝，需要划分为train/test/validation三部分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gd8khc2c43d",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Create domain-specific features that might improve predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gkh9jw5auvi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engineered features\n",
    "def engineer_features(df):\n",
    "    \"\"\"Add domain-specific engineered features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Contact frequency features\n",
    "    df['contact_per_campaign'] = df['campaign'] / (df['previous'] + 1)\n",
    "    df['days_since_last'] = df['pdays'].apply(lambda x: 999 if x == -1 else x)\n",
    "    df['was_contacted_before'] = (df['pdays'] != -1).astype(int)\n",
    "    \n",
    "    # Financial features\n",
    "    df['balance_to_age_ratio'] = df['balance'] / (df['age'] + 1)\n",
    "    df['high_balance'] = (df['balance'] > df['balance'].median()).astype(int)\n",
    "    \n",
    "    # Call duration features (highly predictive but use cautiously)\n",
    "    df['duration_minutes'] = df['duration'] / 60\n",
    "    df['long_call'] = (df['duration'] > 300).astype(int)  # > 5 minutes\n",
    "    \n",
    "    # Time-based features\n",
    "    if 'day' in df.columns:\n",
    "        df['is_month_start'] = (df['day'] <= 10).astype(int)\n",
    "        df['is_month_end'] = (df['day'] >= 20).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "X_train_eng = engineer_features(X_train)\n",
    "X_test_eng = engineer_features(X_test)\n",
    "\n",
    "print(f\"Features after engineering: {X_train_eng.shape[1]}\")\n",
    "print(f\"New features: {set(X_train_eng.columns) - set(X_train.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h6i9yq5dnmi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update preprocessing for engineered features\n",
    "categorical_cols_eng = X_train_eng.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "numeric_cols_eng = [col for col in X_train_eng.columns if col not in categorical_cols_eng]\n",
    "\n",
    "preprocess_eng = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"categorical\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols_eng),\n",
    "        (\"numeric\", StandardScaler(), numeric_cols_eng),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Categorical features: {len(categorical_cols_eng)}\")\n",
    "print(f\"Numeric features: {len(numeric_cols_eng)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa8f563",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad7a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold(probs, y_true, search=np.linspace(0.1, 0.9, 81)):\n",
    "    \"\"\"Find threshold that maximizes F1 score\"\"\"\n",
    "    scores = [(thr, f1_score(y_true, (probs >= thr).astype(int))) for thr in search]\n",
    "    return max(scores, key=lambda x: x[1])\n",
    "\n",
    "def find_best_threshold_pr_curve(probs, y_true):\n",
    "    \"\"\"Find threshold using precision-recall curve\"\"\"\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, probs)\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
    "    return best_threshold, f1_scores[best_idx]\n",
    "\n",
    "def evaluate(name, probs, y_true, threshold=None, use_pr_curve=True):\n",
    "    \"\"\"Evaluate model with comprehensive metrics\"\"\"\n",
    "    if threshold is None:\n",
    "        if use_pr_curve:\n",
    "            threshold, _ = find_best_threshold_pr_curve(probs, y_true)\n",
    "        else:\n",
    "            threshold, _ = find_best_threshold(probs, y_true)\n",
    "    \n",
    "    preds = (probs >= threshold).astype(int)\n",
    "    acc = accuracy_score(y_true, preds)\n",
    "    f1 = f1_score(y_true, preds)\n",
    "    precision = precision_score(y_true, preds)\n",
    "    recall = recall_score(y_true, preds)\n",
    "    roc_auc = roc_auc_score(y_true, probs)\n",
    "    \n",
    "    print(f\"\\n{name} @ threshold {threshold:.3f}\")\n",
    "    print(f\"  Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1:        {f1:.4f}\")\n",
    "    print(f\"  ROC AUC:   {roc_auc:.4f}\")\n",
    "    \n",
    "    return preds, threshold, {\n",
    "        'name': name,\n",
    "        'threshold': threshold,\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ac5eba",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression (one-hot + class weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03860180",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", clone(preprocess_eng)),\n",
    "        (\"model\", LogisticRegression(max_iter=1000, class_weight=\"balanced\", C=0.1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "log_pipeline.fit(X_train_eng, y_train)\n",
    "log_probs = log_pipeline.predict_proba(X_test_eng)[:, 1]\n",
    "log_preds, log_threshold, log_metrics = evaluate(\"Logistic Regression\", log_probs, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f16a8f",
   "metadata": {},
   "source": [
    "## 5. Tuned XGBoost (best current performer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w71qi00vuxe",
   "metadata": {},
   "source": [
    "## 5a. XGBoost with SMOTE (to handle class imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h6bhlqiwemw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with SMOTE oversampling\n",
    "smote_xgb_clf = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=5,\n",
    "    min_child_weight=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    gamma=0.15,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.5,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    ")\n",
    "\n",
    "smote_xgb_pipeline = ImbPipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", clone(preprocess_eng)),\n",
    "        (\"smote\", SMOTE(random_state=42, k_neighbors=5)),\n",
    "        (\"model\", smote_xgb_clf),\n",
    "    ]\n",
    ")\n",
    "\n",
    "smote_xgb_pipeline.fit(X_train_eng, y_train)\n",
    "smote_xgb_probs = smote_xgb_pipeline.predict_proba(X_test_eng)[:, 1]\n",
    "smote_xgb_preds, smote_xgb_threshold, smote_xgb_metrics = evaluate(\"XGBoost + SMOTE\", smote_xgb_probs, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nwbk8i29n6",
   "metadata": {},
   "source": [
    "## 5b. Random Forest with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w3ew4vn7l4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with SMOTE\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "smote_rf_pipeline = ImbPipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", clone(preprocess_eng)),\n",
    "        (\"smote\", SMOTE(random_state=42, k_neighbors=5)),\n",
    "        (\"model\", rf_clf),\n",
    "    ]\n",
    ")\n",
    "\n",
    "smote_rf_pipeline.fit(X_train_eng, y_train)\n",
    "smote_rf_probs = smote_rf_pipeline.predict_proba(X_test_eng)[:, 1]\n",
    "smote_rf_preds, smote_rf_threshold, smote_rf_metrics = evaluate(\"Random Forest + SMOTE\", smote_rf_probs, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bax69h1xs5r",
   "metadata": {},
   "source": [
    "## 5c. LightGBM with SMOTE (often best for imbalanced data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wlkx26l2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM with SMOTE (often superior for imbalanced datasets)\n",
    "lgbm_clf = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=6,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=20,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "smote_lgbm_pipeline = ImbPipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", clone(preprocess_eng)),\n",
    "        (\"smote\", SMOTE(random_state=42, k_neighbors=5)),\n",
    "        (\"model\", lgbm_clf),\n",
    "    ]\n",
    ")\n",
    "\n",
    "smote_lgbm_pipeline.fit(X_train_eng, y_train)\n",
    "smote_lgbm_probs = smote_lgbm_pipeline.predict_proba(X_test_eng)[:, 1]\n",
    "smote_lgbm_preds, smote_lgbm_threshold, smote_lgbm_metrics = evaluate(\"LightGBM + SMOTE\", smote_lgbm_probs, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f168ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=5,\n",
    "    min_child_weight=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    gamma=0.15,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.5,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    scale_pos_weight=pos_weight,\n",
    "    tree_method=\"hist\",\n",
    ")\n",
    "\n",
    "xgb_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", clone(preprocess_eng)),\n",
    "        (\"model\", xgb_clf),\n",
    "    ]\n",
    ")\n",
    "\n",
    "xgb_pipeline.fit(X_train_eng, y_train)\n",
    "xgb_probs = xgb_pipeline.predict_proba(X_test_eng)[:, 1]\n",
    "xgb_preds, xgb_threshold, xgb_metrics = evaluate(\"XGBoost (tuned)\", xgb_probs, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7891bd8c",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lw0yjuc82h",
   "metadata": {},
   "source": [
    "## 5d. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876rfj9rzsw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "all_metrics = [log_metrics, xgb_metrics, smote_xgb_metrics, smote_rf_metrics, smote_lgbm_metrics]\n",
    "comparison_df = pd.DataFrame(all_metrics)\n",
    "comparison_df = comparison_df.sort_values('f1', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON (sorted by F1 score)\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "metrics_to_plot = ['f1', 'precision', 'recall']\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[idx]\n",
    "    comparison_df_sorted = comparison_df.sort_values(metric, ascending=True)\n",
    "    ax.barh(comparison_df_sorted['name'], comparison_df_sorted[metric])\n",
    "    ax.set_xlabel(metric.capitalize())\n",
    "    ax.set_title(f'{metric.capitalize()} Comparison')\n",
    "    ax.set_xlim([0, 1])\n",
    "    \n",
    "plt.tight_layout()\n",
    "comparison_plot_path = PLOTS_DIR / \"model_comparison.png\"\n",
    "plt.savefig(comparison_plot_path)\n",
    "plt.show()\n",
    "print(f\"\\nSaved comparison plot to {comparison_plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823720cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    outfile = PLOTS_DIR / f\"{title.replace(' ', '_').lower()}_confusion_matrix.png\"\n",
    "    plt.savefig(outfile)\n",
    "    plt.show()\n",
    "    print(f\"Saved confusion matrix to {outfile}\")\n",
    "\n",
    "# Plot confusion matrices for all models\n",
    "model_results = [\n",
    "    (\"Logistic Regression\", log_preds, log_threshold),\n",
    "    (\"XGBoost\", xgb_preds, xgb_threshold),\n",
    "    (\"XGBoost + SMOTE\", smote_xgb_preds, smote_xgb_threshold),\n",
    "    (\"Random Forest + SMOTE\", smote_rf_preds, smote_rf_threshold),\n",
    "    (\"LightGBM + SMOTE\", smote_lgbm_preds, smote_lgbm_threshold),\n",
    "]\n",
    "\n",
    "for name, preds, threshold in model_results:\n",
    "    plot_confusion(y_test, preds, f\"{name} (thr={threshold:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d7cb9e",
   "metadata": {},
   "source": [
    "## 7. Persist Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a0d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all models\n",
    "models_to_save = {\n",
    "    \"logistic_regression\": {\"pipeline\": log_pipeline, \"threshold\": log_threshold},\n",
    "    \"xgboost\": {\"pipeline\": xgb_pipeline, \"threshold\": xgb_threshold},\n",
    "    \"xgboost_smote\": {\"pipeline\": smote_xgb_pipeline, \"threshold\": smote_xgb_threshold},\n",
    "    \"random_forest_smote\": {\"pipeline\": smote_rf_pipeline, \"threshold\": smote_rf_threshold},\n",
    "    \"lightgbm_smote\": {\"pipeline\": smote_lgbm_pipeline, \"threshold\": smote_lgbm_threshold},\n",
    "}\n",
    "\n",
    "for model_name, model_data in models_to_save.items():\n",
    "    model_path = MODELS_DIR / f\"{model_name}.pkl\"\n",
    "    joblib.dump(model_data, model_path)\n",
    "    print(f\"Saved {model_name} to {model_path}\")\n",
    "\n",
    "# Identify and save best model\n",
    "best_model_name = comparison_df.iloc[0]['name']\n",
    "print(f\"\\nBest model by F1 score: {best_model_name}\")\n",
    "print(f\"F1 Score: {comparison_df.iloc[0]['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d10e38c",
   "metadata": {},
   "source": [
    "## 8. Generate Predictions and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac88c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from all models for comparison\n",
    "pred_output = pd.DataFrame({\n",
    "    'actual': y_test,\n",
    "    'log_reg_prob': log_probs,\n",
    "    'log_reg_pred': log_preds,\n",
    "    'xgb_prob': xgb_probs,\n",
    "    'xgb_pred': xgb_preds,\n",
    "    'xgb_smote_prob': smote_xgb_probs,\n",
    "    'xgb_smote_pred': smote_xgb_preds,\n",
    "    'rf_smote_prob': smote_rf_probs,\n",
    "    'rf_smote_pred': smote_rf_preds,\n",
    "    'lgbm_smote_prob': smote_lgbm_probs,\n",
    "    'lgbm_smote_pred': smote_lgbm_preds,\n",
    "})\n",
    "\n",
    "predictions_path = PREDICTIONS_DIR / \"classification_predictions.csv\"\n",
    "pred_output.to_csv(predictions_path, index=False)\n",
    "print(f\"Saved predictions to {predictions_path}\")\n",
    "print(f\"Prediction file shape: {pred_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53021071",
   "metadata": {},
   "source": [
    "## 9. Model Interpretability with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ea3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis for the best performing SMOTE model (LightGBM or XGBoost)\n",
    "# Use LightGBM SMOTE if it has the best F1, otherwise use XGBoost SMOTE\n",
    "best_tree_model_name = comparison_df[comparison_df['name'].str.contains('SMOTE')].iloc[0]['name']\n",
    "\n",
    "if 'LightGBM' in best_tree_model_name:\n",
    "    shap_pipeline = smote_lgbm_pipeline\n",
    "    model_label = \"LightGBM + SMOTE\"\n",
    "elif 'XGBoost' in best_tree_model_name:\n",
    "    shap_pipeline = smote_xgb_pipeline\n",
    "    model_label = \"XGBoost + SMOTE\"\n",
    "else:\n",
    "    shap_pipeline = smote_rf_pipeline\n",
    "    model_label = \"Random Forest + SMOTE\"\n",
    "\n",
    "print(f\"Generating SHAP values for: {model_label}\")\n",
    "\n",
    "feature_names = shap_pipeline.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "X_test_encoded = shap_pipeline.named_steps[\"preprocess\"].transform(X_test_eng)\n",
    "\n",
    "sample_size = min(1000, X_test_encoded.shape[0])\n",
    "sample_indices = np.random.RandomState(42).choice(\n",
    "    X_test_encoded.shape[0], sample_size, replace=False\n",
    ")\n",
    "X_sample = X_test_encoded[sample_indices]\n",
    "\n",
    "if hasattr(X_sample, \"toarray\"):\n",
    "    X_sample = X_sample.toarray()\n",
    "\n",
    "explainer = shap.TreeExplainer(shap_pipeline.named_steps[\"model\"])\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    feature_names=feature_names,\n",
    "    plot_type=\"bar\",\n",
    "    max_display=15,\n",
    "    show=False,\n",
    ")\n",
    "plt.tight_layout()\n",
    "shap_plot_path = PLOTS_DIR / f\"{model_label.lower().replace(' ', '_')}_shap_summary_bar.png\"\n",
    "plt.savefig(shap_plot_path, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"Saved SHAP summary plot to {shap_plot_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-mining-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
