{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb77bb2",
   "metadata": {},
   "source": [
    "# DecisionTree\n",
    "Below we give the code of the classification tree and the regression tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e87c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e48dc7c",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd4d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_function_1: classification, entropy\n",
    "def Entropy(y):\n",
    "    label_dic = Counter(y) # {label: counts}\n",
    "    n = len(y)\n",
    "    entropy = sum(-x/n*np.log2(x/n) for x in label_dic.values())\n",
    "    return entropy\n",
    "\n",
    "# loss_fucntion_2: classification, gini index\n",
    "def Gini(y):\n",
    "    label_dic = Counter(y) # {label: counts}\n",
    "    n = len(y)\n",
    "    gini = 1 - sum(np.square(x/n) for x in label_dic.values())\n",
    "    return gini\n",
    "\n",
    "# loss_function_3: regression, variance(l2_norm estimated by the mean value)\n",
    "\n",
    "# loss_function_4: regression, variance by median\n",
    "def Var_median(y):\n",
    "    median = np.median(y)\n",
    "    loss = np.mean((y - median)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ec8c28",
   "metadata": {},
   "source": [
    "### Value Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6519da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Esitimator: most common vote\n",
    "def most_common_vote(y):\n",
    "    label_dict = Counter(y)\n",
    "    most_common_label = label_dict.most_common(1)[0][0]\n",
    "    return most_common_label\n",
    "\n",
    "# Regression Estimator: mean or median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c9b11ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    # initialize a tree\n",
    "    def __init__(self, loss_function, leaf_value_estimator, max_depth=5,current_depth=0,min_sample=5,loss_threshold=1e-5):\n",
    "        self.loss_function = loss_function # Classification: Gini or Entropy; Regression: MSE\n",
    "        self.leaf_value_estimator = leaf_value_estimator\n",
    "        self.max_depth = max_depth\n",
    "        self.current_depth = current_depth\n",
    "        self.min_sample = min_sample\n",
    "        self.loss_threshold = loss_threshold\n",
    "        # tree structure\n",
    "        self.split_id = None\n",
    "        self.split_value = None\n",
    "        self.isleaf = None\n",
    "        self.left = None\n",
    "        self.right = None \n",
    "        self.value = None \n",
    "\n",
    "    # Choose the feature: run if the number of remaining features > 0 and the classification has not meet the standards\n",
    "    def fit(self, X, y):\n",
    "        num_sample, num_feature = X.shape\n",
    "        isunique = (len(np.unique(y)) == 1)\n",
    "        # If the number of remaining features = 0 or the classification has meet the standards, return as a leaf node\n",
    "        # Only the leaf node has the value\n",
    "        if self.current_depth >= self.max_depth or num_sample <= self.min_sample or isunique or self.loss_function(y)<self.loss_threshold:\n",
    "            self.isleaf = True\n",
    "            self.value = self.leaf_value_estimator(y)\n",
    "            return self\n",
    "        # Else, split and recurse to left and right sub-trees\n",
    "        best_loss = self.loss_function(y)\n",
    "        best_split_id = None\n",
    "        best_split_position = None\n",
    "        best_split_value = None\n",
    "        best_X_left = None\n",
    "        best_X_right = None\n",
    "        best_y_left = None\n",
    "        best_y_right = None\n",
    "        num_feature = X.shape[1]\n",
    "        y_copied = y.reshape(-1,1)\n",
    "        Xy = np.concatenate([X, y_copied], 1)\n",
    "        for feature_id in range(num_feature):\n",
    "            # sort by given feature\n",
    "            Xy_sorted = np.array(sorted(Xy, key=lambda x: x[feature_id])) \n",
    "            # choose the best split value of this feature\n",
    "            for split_position in range(len(Xy_sorted)-1):\n",
    "                X_left = Xy_sorted[:split_position+1,:-1]\n",
    "                X_right = Xy_sorted[split_position+1:,:-1]\n",
    "                y_left = Xy_sorted[:split_position+1,-1]\n",
    "                y_right = Xy_sorted[split_position+1:,-1]\n",
    "                # calculate loss\n",
    "                loss_left = len(y_left)/len(y) * self.loss_function(y_left)\n",
    "                loss_right = len(y_right)/len(y) * self.loss_function(y_right)\n",
    "                # update the split position\n",
    "                if (loss_left + loss_right < best_loss):\n",
    "                    best_split_id = feature_id\n",
    "                    best_split_position = split_position\n",
    "                    best_split_value = Xy_sorted[best_split_position, best_split_id]\n",
    "                    best_loss = loss_left + loss_right\n",
    "                    best_X_left = X_left\n",
    "                    best_X_right = X_right\n",
    "                    best_y_left = y_left\n",
    "                    best_y_right = y_right\n",
    "        # Recurese and construct the decision tree\n",
    "        if best_split_id != None:\n",
    "            self.left = DecisionTree(self.loss_function, self.leaf_value_estimator, self.max_depth, current_depth=self.current_depth + 1, min_sample=self.min_sample, loss_threshold=self.loss_threshold)\n",
    "            self.left.fit(best_X_left, best_y_left)\n",
    "            self.right = DecisionTree(self.loss_function, self.leaf_value_estimator, self.max_depth, current_depth=self.current_depth + 1, min_sample=self.min_sample, loss_threshold=self.loss_threshold)\n",
    "            self.right.fit(best_X_right, best_y_right)\n",
    "            \n",
    "            self.split_id = best_split_id\n",
    "            self.split_value = best_split_value\n",
    "        else: \n",
    "            self.isleaf = True\n",
    "            self.value = self.leaf_value_estimator(y)\n",
    "        return self\n",
    "\n",
    "    # Predict the label/value given a new instance\n",
    "    def predict(self, X_new):\n",
    "        # Only leaf node has the value\n",
    "        if self.isleaf:\n",
    "            return self.value\n",
    "        else:\n",
    "            if X_new[self.split_id] <= self.split_value:\n",
    "                return self.left.predict(X_new)\n",
    "            else:\n",
    "                return self.right.predict(X_new)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10020013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/xuguangjie/Desktop/PhD Courses/博二上/数据挖掘/大作业/data-mining\n",
      "Outputs directory: /Users/xuguangjie/Desktop/PhD Courses/博二上/数据挖掘/大作业/data-mining/outputs\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Resolve project paths and organize outputs\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if not (PROJECT_ROOT / \"datasets\").exists() and (PROJECT_ROOT.parent / \"datasets\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "if not (PROJECT_ROOT / \"datasets\").exists():\n",
    "    raise FileNotFoundError(\"Could not locate datasets folder. Run from project root or src directory.\")\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"datasets\" / \"boston-housing\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n",
    "PLOTS_DIR = OUTPUT_DIR / \"plots\"\n",
    "MODELS_DIR = OUTPUT_DIR / \"models\"\n",
    "PREDICTIONS_DIR = OUTPUT_DIR / \"predictions\"\n",
    "for path in [OUTPUT_DIR, PLOTS_DIR, MODELS_DIR, PREDICTIONS_DIR]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Outputs directory: {OUTPUT_DIR}\")\n",
    "data_path = DATA_DIR / \"HousingData.csv\"\n",
    "df = pd.read_csv(data_path, sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa5a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.iloc[:,:-1])\n",
    "y = np.array(df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50b6ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regtree = DecisionTree(np.var,np.mean, loss_threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8734fbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DecisionTree at 0x10fdfae00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regtree.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7a74b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(34.15555555555555)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regtree.predict(X[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af6182bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(32.9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87cf07b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/xuguangjie/Desktop/PhD Courses/博二上/数据挖掘/大作业/data-mining\n",
      "Outputs directory: /Users/xuguangjie/Desktop/PhD Courses/博二上/数据挖掘/大作业/data-mining/outputs\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Resolve project paths and organize outputs\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if not (PROJECT_ROOT / \"datasets\").exists() and (PROJECT_ROOT.parent / \"datasets\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "if not (PROJECT_ROOT / \"datasets\").exists():\n",
    "    raise FileNotFoundError(\"Could not locate datasets folder. Run from project root or src directory.\")\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"datasets\" / \"bank-marketing\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n",
    "PLOTS_DIR = OUTPUT_DIR / \"plots\"\n",
    "MODELS_DIR = OUTPUT_DIR / \"models\"\n",
    "PREDICTIONS_DIR = OUTPUT_DIR / \"predictions\"\n",
    "for path in [OUTPUT_DIR, PLOTS_DIR, MODELS_DIR, PREDICTIONS_DIR]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Outputs directory: {OUTPUT_DIR}\")\n",
    "data_path = DATA_DIR / \"bank-full.csv\"\n",
    "df = pd.read_csv(data_path, sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b7a385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array(df.iloc[:,:-1])\n",
    "y = np.array(df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98310c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:400]\n",
    "y_train = y[:400]\n",
    "clstree = DecisionTree(loss_function=Entropy, leaf_value_estimator=most_common_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f3591ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DecisionTree at 0x111e1d0f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clstree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f43a83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clstree.predict(X[401])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "672bdf0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7255713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionTree():\n",
    "    loss_function_dict = {\n",
    "        \"MSE_mean\": np.var,\n",
    "        \"MSE_median\":Var_median\n",
    "    }\n",
    "    estimator_dict = {\n",
    "        \"mean\":np.mean,\n",
    "        \"median\": np.median\n",
    "    }\n",
    "\n",
    "    # initialize a tree\n",
    "    def __init__(self, loss_function=\"MSE_mean\", leaf_value_estimator=\"mean\", max_depth=5,current_depth=0,min_sample=5,loss_threshold=1e-5):\n",
    "        try:\n",
    "            self.loss_function = self.loss_function_dict[loss_function]\n",
    "            self.leaf_value_estimator = self.estimator_dict[leaf_value_estimator]\n",
    "        except KeyError:\n",
    "            raise ValueError(\n",
    "            f\"Unknown loss_function '{loss_function}'. \"\n",
    "            f\"Available: {list(self.loss_function_dict.keys())}\"\n",
    "        )\n",
    "        try:\n",
    "            self.leaf_value_estimator = self.estimator_dict[leaf_value_estimator]\n",
    "        except KeyError:\n",
    "            raise ValueError(\n",
    "            f\"Unknown leaf_value_estimator '{leaf_value_estimator}'. \"\n",
    "            f\"Available: {list(self.estimator_dict.keys())}\"\n",
    "        )\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.current_depth = current_depth\n",
    "        self.min_sample = min_sample\n",
    "        self.loss_threshold = loss_threshold\n",
    "        # tree structure\n",
    "        self.split_id = None\n",
    "        self.split_value = None\n",
    "        self.isleaf = None\n",
    "        self.left = None\n",
    "        self.right = None \n",
    "        self.value = None \n",
    "\n",
    "    # Check the node infomation\n",
    "    def node_info(self):\n",
    "        return {\n",
    "            \"depth\": self.current_depth,\n",
    "            \"is_leaf\": self.isleaf,\n",
    "            \"split_id\": self.split_id,\n",
    "            \"split_value\": self.split_value,\n",
    "            \"value\": self.value,\n",
    "        }\n",
    "\n",
    "    # Choose the feature: run if the number of remaining features > 0 and the classification has not meet the standards\n",
    "    def fit(self, X, y):\n",
    "        num_sample, num_feature = X.shape\n",
    "        isunique = (len(np.unique(y)) == 1)\n",
    "        # If the number of remaining features = 0 or the classification has meet the standards, return as a leaf node\n",
    "        # Only the leaf node has the value\n",
    "        if self.current_depth >= self.max_depth or num_sample <= self.min_sample or isunique or self.loss_function(y)<self.loss_threshold:\n",
    "            self.isleaf = True\n",
    "            self.value = self.leaf_value_estimator(y)\n",
    "            return self\n",
    "        # Else, split and recurse to left and right sub-trees\n",
    "        best_loss = self.loss_function(y)\n",
    "        best_split_id = None\n",
    "        best_split_position = None\n",
    "        best_split_value = None\n",
    "        best_X_left = None\n",
    "        best_X_right = None\n",
    "        best_y_left = None\n",
    "        best_y_right = None\n",
    "        num_feature = X.shape[1]\n",
    "        # y is (n,)\n",
    "        y_copied = y.reshape(-1,1)\n",
    "        Xy = np.concatenate([X, y_copied], 1)\n",
    "        # RegressionTree can use the same feature in different nodes\n",
    "        for feature_id in range(num_feature):\n",
    "            # sort by given feature\n",
    "            Xy_sorted = np.array(sorted(Xy, key=lambda x: x[feature_id])) \n",
    "            # choose the best split value of this feature\n",
    "            for split_position in range(len(Xy_sorted)-1):\n",
    "                X_left = Xy_sorted[:split_position+1,:-1]\n",
    "                X_right = Xy_sorted[split_position+1:,:-1]\n",
    "                y_left = Xy_sorted[:split_position+1,-1]\n",
    "                y_right = Xy_sorted[split_position+1:,-1]\n",
    "                # calculate loss\n",
    "                loss_left = len(y_left)/len(y) * self.loss_function(y_left)\n",
    "                loss_right = len(y_right)/len(y) * self.loss_function(y_right)\n",
    "                # update the split position\n",
    "                if (loss_left + loss_right < best_loss):\n",
    "                    best_split_id = feature_id\n",
    "                    best_split_position = split_position\n",
    "                    best_split_value = Xy_sorted[best_split_position, best_split_id]\n",
    "                    best_loss = loss_left + loss_right\n",
    "                    best_X_left = X_left\n",
    "                    best_X_right = X_right\n",
    "                    best_y_left = y_left\n",
    "                    best_y_right = y_right\n",
    "        # Recurese and construct the decision tree\n",
    "        if best_split_id != None:\n",
    "            self.left = DecisionTree(self.loss_function, self.leaf_value_estimator, self.max_depth, current_depth=self.current_depth + 1, min_sample=self.min_sample, loss_threshold=self.loss_threshold)\n",
    "            self.left.fit(best_X_left, best_y_left)\n",
    "            self.right = DecisionTree(self.loss_function, self.leaf_value_estimator, self.max_depth, current_depth=self.current_depth + 1, min_sample=self.min_sample, loss_threshold=self.loss_threshold)\n",
    "            self.right.fit(best_X_right, best_y_right)\n",
    "            \n",
    "            self.split_id = best_split_id\n",
    "            self.split_value = best_split_value\n",
    "        else: \n",
    "            self.isleaf = True\n",
    "            self.value = self.leaf_value_estimator(y)\n",
    "        return self\n",
    "\n",
    "    # Predict the value given a new instance\n",
    "    def predict(self, X_new):\n",
    "        # Only leaf node has the value\n",
    "        if self.isleaf:\n",
    "            return self.value\n",
    "        else:\n",
    "            if X_new[self.split_id] <= self.split_value:\n",
    "                return self.left.predict(X_new)\n",
    "            else:\n",
    "                return self.right.predict(X_new)\n",
    "    \n",
    "    # Predict the value given a batch of new instances\n",
    "    def predict_batch(self,X_new):\n",
    "        X = np.array(X_new)\n",
    "        preds = [self.predict(x) for x in X]\n",
    "        return np.array(preds)            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-mining-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
