{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb77bb2",
   "metadata": {},
   "source": [
    "# DecisionTree\n",
    "Below we give the code of the classification tree and the regression tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e87c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e48dc7c",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdd4d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_function_1: classification, entropy\n",
    "def Entropy(y):\n",
    "    label_dic = Counter(y) # {label: counts}\n",
    "    n = len(y)\n",
    "    entropy = sum(-x/n*np.log2(x/n) for x in label_dic.values())\n",
    "    return entropy\n",
    "\n",
    "# loss_fucntion_2: classification, gini index\n",
    "def Gini(y):\n",
    "    label_dic = Counter(y) # {label: counts}\n",
    "    n = len(y)\n",
    "    gini = 1 - sum(np.square(x/n) for x in label_dic.values())\n",
    "    return gini\n",
    "\n",
    "# loss_function_3: regression, variance(l2_norm estimated by the mean value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ec8c28",
   "metadata": {},
   "source": [
    "### Value Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6519da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Esitimator: most common vote\n",
    "def most_common_vote(y):\n",
    "    label_dict = Counter(y)\n",
    "    most_common_label = label_dict.most_common(1)[0][0]\n",
    "    return most_common_label\n",
    "\n",
    "# Regression Estimator: mean or median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9b11ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    # initialize a tree\n",
    "    def __init__(self, loss_function, leaf_value_estimator, max_depth=5,current_depth=0,min_sample=5,loss_threshold=1e-5):\n",
    "        self.loss_function = loss_function # Classification: Gini or Entropy; Regression: MSE\n",
    "        self.leaf_value_estimator = leaf_value_estimator\n",
    "        self.max_depth = max_depth\n",
    "        self.current_depth = current_depth\n",
    "        self.min_sample = min_sample\n",
    "        self.loss_threshold = loss_threshold\n",
    "        # tree structure\n",
    "        self.split_id = None\n",
    "        self.split_value = None\n",
    "        self.isleaf = None\n",
    "        self.left = None\n",
    "        self.right = None \n",
    "        self.value = None \n",
    "\n",
    "    # Choose the feature: run if the number of remaining features > 0 and the classification has not meet the standards\n",
    "    def fit(self, X, y):\n",
    "        num_sample, num_feature = X.shape\n",
    "        isunique = (len(np.unique(y)) == 1)\n",
    "        # If the number of remaining features = 0 or the classification has meet the standards, return as a leaf node\n",
    "        # Only the leaf node has the value\n",
    "        if self.current_depth >= self.max_depth or num_sample <= self.min_sample or isunique or self.loss_function(y)<self.loss_threshold:\n",
    "            self.isleaf = True\n",
    "            self.value = self.leaf_value_estimator(y)\n",
    "            return self\n",
    "        # Else, split and recurse to left and right sub-trees\n",
    "        best_loss = self.loss_function(y)\n",
    "        best_split_id = None\n",
    "        best_split_position = None\n",
    "        best_split_value = None\n",
    "        best_X_left = None\n",
    "        best_X_right = None\n",
    "        best_y_left = None\n",
    "        best_y_right = None\n",
    "        num_feature = X.shape[1]\n",
    "        Xy = np.concatenate([X, y], 1)\n",
    "        for feature_id in range(num_feature):\n",
    "            # sort by given feature\n",
    "            Xy_sorted = np.array(sorted(Xy, key=lambda x: x[feature_id])) \n",
    "            # choose the best split value of this feature\n",
    "            for split_position in range(len(Xy_sorted)-1):\n",
    "                X_left = Xy_sorted[:split_position+1,:-1]\n",
    "                X_right = Xy_sorted[split_position+1:,:-1]\n",
    "                y_left = Xy_sorted[:split_position+1,-1]\n",
    "                y_right = Xy_sorted[split_position+1:,-1]\n",
    "                # calculate loss\n",
    "                loss_left = len(y_left)/len(y) * self.loss_function(y_left)\n",
    "                loss_right = len(y_right)/len(y) * self.loss_function(y_right)\n",
    "                # update the split position\n",
    "                if (loss_left + loss_right < best_loss):\n",
    "                    best_split_id = feature_id\n",
    "                    best_split_position = split_position\n",
    "                    best_split_value = Xy_sorted[best_split_position, best_split_id]\n",
    "                    best_loss = loss_left + loss_right\n",
    "                    best_X_left = X_left\n",
    "                    best_X_right = X_right\n",
    "                    best_y_left = y_left\n",
    "                    best_y_right = y_right\n",
    "        # Recurese and construct the decision tree\n",
    "        if best_split_id != None:\n",
    "            self.left = DecisionTree(self.loss_function, self.leaf_value_estimator, self.max_depth, current_depth=self.current_depth + 1, min_sample=self.min_sample, loss_threshold=self.loss_threshold)\n",
    "            self.left.fit(best_X_left, best_y_left)\n",
    "            self.right = DecisionTree(self.loss_function, self.leaf_value_estimator, self.max_depth, current_depth=self.current_depth + 1, min_sample=self.min_sample, loss_threshold=self.loss_threshold)\n",
    "            self.right.fit(best_X_right, best_y_right)\n",
    "            \n",
    "            self.split_id = best_split_id\n",
    "            self.split_value = best_split_value\n",
    "        else: \n",
    "            self.isleaf = True\n",
    "            self.value = self.leaf_value_estimator(y)\n",
    "        return self\n",
    "\n",
    "    # Predict the label/value given a new instance\n",
    "    def predict(self, X_new):\n",
    "        # Only leaf node has the value\n",
    "        if self.isleaf:\n",
    "            return self.value\n",
    "        else:\n",
    "            if X_new[self.split_id] <= self.split_value:\n",
    "                return self.left.predict(X_new)\n",
    "            else:\n",
    "                return self.right.predict(X_new)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10020013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/xuguangjie/Desktop/PhD Courses/博二上/数据挖掘/大作业/data-mining\n",
      "Outputs directory: /Users/xuguangjie/Desktop/PhD Courses/博二上/数据挖掘/大作业/data-mining/outputs\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Resolve project paths and organize outputs\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if not (PROJECT_ROOT / \"datasets\").exists() and (PROJECT_ROOT.parent / \"datasets\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "if not (PROJECT_ROOT / \"datasets\").exists():\n",
    "    raise FileNotFoundError(\"Could not locate datasets folder. Run from project root or src directory.\")\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"datasets\" / \"boston-housing\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n",
    "PLOTS_DIR = OUTPUT_DIR / \"plots\"\n",
    "MODELS_DIR = OUTPUT_DIR / \"models\"\n",
    "PREDICTIONS_DIR = OUTPUT_DIR / \"predictions\"\n",
    "for path in [OUTPUT_DIR, PLOTS_DIR, MODELS_DIR, PREDICTIONS_DIR]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Outputs directory: {OUTPUT_DIR}\")\n",
    "data_path = DATA_DIR / \"HousingData.csv\"\n",
    "df = pd.read_csv(data_path, sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aa5a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.iloc[:,:-1])\n",
    "y = np.array(df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b6ae6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-mining-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
