{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c3d546",
   "metadata": {},
   "source": [
    "# Bank Marketing Campaign Classification\n",
    "\n",
    "This notebook builds a classification pipeline to predict whether a customer will subscribe to a term deposit based on the UCI Bank Marketing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42effcd6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed1ee09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zihanghuang/data-mining/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard library\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn: preprocessing and evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Imbalanced learning\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Model persistence\n",
    "import joblib\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Model interpretability\n",
    "import shap\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2608781",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Configure project paths and load the Bank Marketing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b6cddc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/zihanghuang/data-mining\n",
      "Outputs directory: /Users/zihanghuang/data-mining/outputs\n"
     ]
    }
   ],
   "source": [
    "# Resolve project paths\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if not (PROJECT_ROOT / \"datasets\").exists() and (PROJECT_ROOT.parent / \"datasets\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "if not (PROJECT_ROOT / \"datasets\").exists():\n",
    "    raise FileNotFoundError(\"Could not locate datasets folder. Run from project root or src directory.\")\n",
    "\n",
    "# Define directory structure\n",
    "DATA_DIR = PROJECT_ROOT / \"datasets\" / \"bank-marketing\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n",
    "PLOTS_DIR = OUTPUT_DIR / \"plots\"\n",
    "MODELS_DIR = OUTPUT_DIR / \"models\"\n",
    "PREDICTIONS_DIR = OUTPUT_DIR / \"predictions\"\n",
    "\n",
    "# Create output directories\n",
    "for path in [PLOTS_DIR, MODELS_DIR, PREDICTIONS_DIR]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Outputs directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d162f1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 45,211 rows and 17 columns\n",
      "\n",
      "Target distribution:\n",
      "y\n",
      "no     0.883015\n",
      "yes    0.116985\n",
      "\n",
      "Class imbalance ratio: 7.55:1\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data_path = DATA_DIR / \"bank-full.csv\"\n",
    "df_raw = pd.read_csv(data_path, sep=\";\")\n",
    "\n",
    "print(f\"Loaded {df_raw.shape[0]:,} rows and {df_raw.shape[1]} columns\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df_raw[\"y\"].value_counts(normalize=True).rename(\"proportion\").to_string())\n",
    "print(f\"\\nClass imbalance ratio: {df_raw['y'].value_counts()['no'] / df_raw['y'].value_counts()['yes']:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea9b859",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Outlier Removal\n",
    "Remove extreme outliers (z-score > 3) from numeric columns to reduce noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8366f905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before: 45,211\n",
      "Rows after outlier removal: 44,220\n",
      "Rows removed: 991 (2.2%)\n",
      "\n",
      "Note: 'duration' column dropped (only known post-call, causes data leakage)\n"
     ]
    }
   ],
   "source": [
    "# Remove outliers using z-score method\n",
    "# Keeps more edge cases that may contain valuable signal\n",
    "df = df_raw.copy()\n",
    "outlier_cols = [\"balance\", \"age\", \"campaign\"]\n",
    "\n",
    "# Drop duration column - it's only known after a call ends (data leakage)\n",
    "df = df.drop(columns=[\"duration\"])\n",
    "\n",
    "# Create a combined mask for all outlier conditions (relaxed threshold)\n",
    "outlier_mask = pd.Series(True, index=df.index)\n",
    "for col in outlier_cols:\n",
    "    z_scores = np.abs((df[col] - df[col].mean()) / df[col].std())\n",
    "    outlier_mask &= (z_scores < 4)  # Changed from 3 to 4 (less aggressive)\n",
    "\n",
    "df = df[outlier_mask].reset_index(drop=True)\n",
    "\n",
    "print(f\"Rows before: {df_raw.shape[0]:,}\")\n",
    "print(f\"Rows after outlier removal: {df.shape[0]:,}\")\n",
    "print(f\"Rows removed: {df_raw.shape[0] - df.shape[0]:,} ({100 * (1 - df.shape[0] / df_raw.shape[0]):.1f}%)\")\n",
    "print(f\"\\nNote: 'duration' column dropped (only known post-call, causes data leakage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d223511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features (9): ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
      "Numeric features (6): ['age', 'balance', 'day', 'campaign', 'pdays', 'previous']\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df.drop(columns=\"y\")\n",
    "y = df[\"y\"].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "# Identify column types\n",
    "categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "print(f\"Categorical features ({len(categorical_cols)}): {categorical_cols}\")\n",
    "print(f\"Numeric features ({len(numeric_cols)}): {numeric_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gd8khc2c43d",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Create domain-specific features to improve model predictive power.\n",
    "\n",
    "**Note**: The `duration` feature was removed from the dataset as it represents call duration, which is only known after a call ends and would cause data leakage in a real prediction scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "gkh9jw5auvi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features: 15\n",
      "Engineered features: 34\n",
      "New features added (19): ['balance_per_age', 'contact_intensity', 'contact_recency', 'contacted_and_success', 'has_high_balance', 'has_loan_or_default', 'has_positive_balance', 'high_campaign_effort', 'is_high_conversion_month', 'is_month_end', 'is_month_start', 'pdays_log', 'prev_failure', 'prev_success', 'prev_unknown', 'retired_age', 'total_contacts', 'was_contacted_before', 'young_single']\n"
     ]
    }
   ],
   "source": [
    "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    \n",
    "    # -1 means never contacted, don't use 999 which creates outliers\n",
    "    df[\"was_contacted_before\"] = (df[\"pdays\"] != -1).astype(int)\n",
    "    \n",
    "    # For those contacted before, use log transform (adds 1 to avoid log(0))\n",
    "    # For never contacted, use median of contacted group\n",
    "    contacted_mask = df[\"pdays\"] != -1\n",
    "    if contacted_mask.sum() > 0:\n",
    "        median_pdays = df.loc[contacted_mask, \"pdays\"].median()\n",
    "        df[\"pdays_transformed\"] = df[\"pdays\"].replace(-1, median_pdays)\n",
    "        df[\"pdays_log\"] = np.log1p(df[\"pdays_transformed\"])\n",
    "    else:\n",
    "        df[\"pdays_log\"] = 0\n",
    "    \n",
    "    # Recency buckets, more informative than raw days\n",
    "    df[\"contact_recency\"] = pd.cut(\n",
    "        df[\"pdays\"].replace(-1, 9999),\n",
    "        bins=[-1, 7, 30, 90, 180, 365, 10000],\n",
    "        labels=[\"week\", \"month\", \"quarter\", \"half_year\", \"year\", \"never\"]\n",
    "    ).astype(str)\n",
    "    \n",
    "    # Previous campaign success is extremely predictive (~65% conversion if success)\n",
    "    df[\"prev_success\"] = (df[\"poutcome\"] == \"success\").astype(int)\n",
    "    df[\"prev_failure\"] = (df[\"poutcome\"] == \"failure\").astype(int)\n",
    "    df[\"prev_unknown\"] = (df[\"poutcome\"] == \"unknown\").astype(int)\n",
    "    \n",
    "    # Interaction: contacted before AND had success\n",
    "    df[\"contacted_and_success\"] = (df[\"was_contacted_before\"] & df[\"prev_success\"]).astype(int)\n",
    "    \n",
    "    # === Contact history features ===\n",
    "    df[\"contact_intensity\"] = df[\"campaign\"] / (df[\"previous\"] + 1)\n",
    "    df[\"total_contacts\"] = df[\"campaign\"] + df[\"previous\"]\n",
    "    df[\"high_campaign_effort\"] = (df[\"campaign\"] > df[\"campaign\"].median()).astype(int)\n",
    "    \n",
    "    # === Financial features ===\n",
    "    df[\"balance_per_age\"] = df[\"balance\"] / (df[\"age\"] + 1)\n",
    "    df[\"has_positive_balance\"] = (df[\"balance\"] > 0).astype(int)\n",
    "    df[\"has_high_balance\"] = (df[\"balance\"] > df[\"balance\"].quantile(0.75)).astype(int)\n",
    "    df[\"has_loan_or_default\"] = ((df[\"loan\"] == \"yes\") | (df[\"default\"] == \"yes\")).astype(int)\n",
    "    \n",
    "    # === Demographic interactions ===\n",
    "    df[\"young_single\"] = ((df[\"age\"] < 30) & (df[\"marital\"] == \"single\")).astype(int)\n",
    "    df[\"retired_age\"] = (df[\"age\"] >= 60).astype(int)\n",
    "    \n",
    "    # === Time-based features ===\n",
    "    if \"day\" in df.columns:\n",
    "        df[\"is_month_start\"] = (df[\"day\"] <= 10).astype(int)\n",
    "        df[\"is_month_end\"] = (df[\"day\"] >= 20).astype(int)\n",
    "    \n",
    "    # Month seasonality (certain months have higher conversion)\n",
    "    high_conversion_months = [\"mar\", \"oct\", \"sep\", \"dec\"]\n",
    "    df[\"is_high_conversion_month\"] = df[\"month\"].isin(high_conversion_months).astype(int)\n",
    "    \n",
    "    # Drop intermediate columns\n",
    "    df = df.drop(columns=[\"pdays_transformed\"], errors=\"ignore\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply feature engineering\n",
    "X_engineered = engineer_features(X)\n",
    "\n",
    "new_features = set(X_engineered.columns) - set(X.columns)\n",
    "print(f\"Original features: {len(X.columns)}\")\n",
    "print(f\"Engineered features: {len(X_engineered.columns)}\")\n",
    "print(f\"New features added ({len(new_features)}): {sorted(new_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "h6i9yq5dnmi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: 10\n",
      "Numeric features: 24\n"
     ]
    }
   ],
   "source": [
    "# Update column lists for engineered features\n",
    "categorical_cols_eng = X_engineered.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "numeric_cols_eng = X_engineered.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_cols_eng),\n",
    "        (\"num\", StandardScaler(), numeric_cols_eng),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Categorical features: {len(categorical_cols_eng)}\")\n",
    "print(f\"Numeric features: {len(numeric_cols_eng)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hqwd3zkk6ur",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "Use stratified split to preserve class distribution in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "i74flw68nsr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 26,532 samples (60%)\n",
      "Validation set: 8,844 samples (20%) - for early stopping\n",
      "Test set: 8,844 samples (20%)\n",
      "Positive class weight: 7.50\n",
      "\n",
      "Train class distribution:\n",
      "y\n",
      "no     0.882331\n",
      "yes    0.117669\n"
     ]
    }
   ],
   "source": [
    "# Stratified train/validation/test split\n",
    "# First split: train+val vs test (80/20)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_engineered, y, \n",
    "    test_size=0.2, \n",
    "    random_state=RANDOM_STATE, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Second split: train vs validation (75/25 of remaining = 60/20 overall)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.25,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "# Calculate class weight for imbalanced learning\n",
    "pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples (60%)\")\n",
    "print(f\"Validation set: {X_val.shape[0]:,} samples (20%) - for early stopping\")\n",
    "print(f\"Test set: {X_test.shape[0]:,} samples (20%)\")\n",
    "print(f\"Positive class weight: {pos_weight:.2f}\")\n",
    "print(f\"\\nTrain class distribution:\")\n",
    "print(y_train.value_counts(normalize=True).rename({0: \"no\", 1: \"yes\"}).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa8f563",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "Utility functions for threshold optimization and model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ad7a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_threshold(y_true: np.ndarray, y_proba: np.ndarray) -> tuple[float, float]:\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "    \n",
    "    # Calculate F1 for each threshold (avoid division by zero)\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "    \n",
    "    # Find best threshold (precision_recall_curve returns n+1 values, last has no threshold)\n",
    "    best_idx = np.argmax(f1_scores[:-1])\n",
    "    return thresholds[best_idx], f1_scores[best_idx]\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    name: str, \n",
    "    y_true: np.ndarray, \n",
    "    y_proba: np.ndarray, \n",
    "    threshold: float = None\n",
    ") -> dict:\n",
    "    if threshold is None:\n",
    "        threshold, _ = find_optimal_threshold(y_true, y_proba)\n",
    "    \n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    metrics = {\n",
    "        \"name\": name,\n",
    "        \"threshold\": threshold,\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_proba),\n",
    "        \"predictions\": y_pred,\n",
    "        \"probabilities\": y_proba,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{name} @ threshold {threshold:.3f}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"  Accuracy:  {metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {metrics['recall']:.4f}\")\n",
    "    print(f\"  F1 Score:  {metrics['f1']:.4f}\")\n",
    "    print(f\"  ROC AUC:   {metrics['roc_auc']:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ac5eba",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Train multiple classifiers with different approaches to handle class imbalance:\n",
    "1. **Class weights**: Built-in parameter to penalize misclassification of minority class\n",
    "2. **SMOTE**: Synthetic Minority Over-sampling Technique to balance training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03860180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all results for comparison\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v3qpk0hha8l",
   "metadata": {},
   "source": [
    "## Bayesian Hyperparameter Optimization\n",
    "\n",
    "Use `BayesSearchCV` from scikit-optimize to find optimal hyperparameters for each model. Bayesian optimization is more efficient than grid search as it uses past evaluation results to choose the next hyperparameters to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hfiwz8hhhsm",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Bayesian Optimization imports\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Use stratified k-fold for imbalanced data\n",
    "bayes_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# SMOTE for handling class imbalance (applied only during training in CV)\n",
    "smote = SMOTE(random_state=RANDOM_STATE)\n",
    "\n",
    "# Store Bayesian optimization results\n",
    "bayes_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jnfufql5r3",
   "metadata": {},
   "source": [
    "### Reactive Rule Learner (RRL)\n",
    "\n",
    "RRL is an interpretable rule-based model that learns logical rules from data. It provides transparent decision-making through human-readable rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otxrk7hydn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device for RRL: cpu\n",
      "Preparing engineered features for RRL...\n",
      "RRL Training samples: 26,532\n",
      "RRL Validation samples: 8,844\n",
      "RRL Test samples: 8,844\n",
      "Creating tensors...\n",
      "Discrete features: 40, Continuous features: 24\n",
      "RRL output dimension: 2\n",
      "Starting RRL hyperparameter search...\n",
      "============================================================\n",
      "Testing 27 configurations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zihanghuang/data-mining/venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/zihanghuang/data-mining/venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/zihanghuang/data-mining/venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# RRL Training using preprocessed and engineered features with hyperparameter search\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import importlib\n",
    "import rrl.models\n",
    "from rrl.models import RRL\n",
    "from rrl.utils import DBEncoder\n",
    "from itertools import product\n",
    "\n",
    "# Set device for RRL\n",
    "# Force CPU usage to avoid potential MPS instability/crashes during repeated model initialization\n",
    "rrl_device = torch.device(\"cpu\")\n",
    "print(f\"Using device for RRL: {rrl_device}\", flush=True)\n",
    "\n",
    "# Use engineered features (same as other models)\n",
    "# Create feature info dataframe for DBEncoder from X_engineered\n",
    "print(\"Preparing engineered features for RRL...\", flush=True)\n",
    "f_list = []\n",
    "for col in X_engineered.columns:\n",
    "    if X_engineered[col].dtype == 'object':\n",
    "        f_list.append([col, 'discrete'])\n",
    "    else:\n",
    "        f_list.append([col, 'continuous'])\n",
    "\n",
    "f_df = pd.DataFrame(f_list)\n",
    "\n",
    "# Initialize DBEncoder with engineered features\n",
    "db_enc = DBEncoder(f_df, discrete=False)\n",
    "\n",
    "# Create target dataframe (DBEncoder expects DataFrame)\n",
    "y_train_df = y_train.to_frame(name='y')\n",
    "y_val_df = y_val.to_frame(name='y')\n",
    "y_test_df = y_test.to_frame(name='y')\n",
    "\n",
    "# Fit encoder on training data\n",
    "db_enc.fit(X_train, y_train_df)\n",
    "\n",
    "# Transform all splits\n",
    "X_rrl_train, y_rrl_train = db_enc.transform(X_train, y_train_df, normalized=True, keep_stat=True)\n",
    "X_rrl_val, y_rrl_val = db_enc.transform(X_val, y_val_df, normalized=True, keep_stat=False)\n",
    "X_rrl_test, y_rrl_test = db_enc.transform(X_test, y_test_df, normalized=True, keep_stat=False)\n",
    "\n",
    "print(f\"RRL Training samples: {X_rrl_train.shape[0]:,}\", flush=True)\n",
    "print(f\"RRL Validation samples: {X_rrl_val.shape[0]:,}\", flush=True)\n",
    "print(f\"RRL Test samples: {X_rrl_test.shape[0]:,}\", flush=True)\n",
    "\n",
    "# Create DataLoaders with optimized settings for speed\n",
    "print(\"Creating tensors...\", flush=True)\n",
    "rrl_batch_size = 256\n",
    "\n",
    "# FIX: Explicitly convert to float32 numpy arrays before creating tensors\n",
    "# DBEncoder.transform can return object dtype arrays which cause torch.tensor() to hang\n",
    "X_rrl_train = np.asarray(X_rrl_train, dtype=np.float32)\n",
    "X_rrl_val = np.asarray(X_rrl_val, dtype=np.float32)\n",
    "X_rrl_test = np.asarray(X_rrl_test, dtype=np.float32)\n",
    "y_rrl_train = np.asarray(y_rrl_train, dtype=np.float32)\n",
    "y_rrl_val = np.asarray(y_rrl_val, dtype=np.float32)\n",
    "y_rrl_test = np.asarray(y_rrl_test, dtype=np.float32)\n",
    "\n",
    "# Create tensors using torch.from_numpy (faster than torch.tensor for contiguous arrays)\n",
    "X_train_tensor = torch.from_numpy(X_rrl_train)\n",
    "y_train_tensor = torch.from_numpy(y_rrl_train)\n",
    "X_val_tensor = torch.from_numpy(X_rrl_val)\n",
    "y_val_tensor = torch.from_numpy(y_rrl_val)\n",
    "X_test_tensor = torch.from_numpy(X_rrl_test)\n",
    "y_test_tensor = torch.from_numpy(y_rrl_test)\n",
    "\n",
    "rrl_train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "rrl_val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "rrl_test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "rrl_train_loader = DataLoader(rrl_train_dataset, batch_size=rrl_batch_size, shuffle=True)\n",
    "rrl_val_loader = DataLoader(rrl_val_dataset, batch_size=rrl_batch_size, shuffle=False)\n",
    "rrl_test_loader = DataLoader(rrl_test_dataset, batch_size=rrl_batch_size, shuffle=False)\n",
    "\n",
    "discrete_flen = db_enc.discrete_flen\n",
    "continuous_flen = db_enc.continuous_flen\n",
    "rrl_output_dim = y_rrl_train.shape[1]  # One-hot encoded length\n",
    "\n",
    "print(f\"Discrete features: {discrete_flen}, Continuous features: {continuous_flen}\", flush=True)\n",
    "print(f\"RRL output dimension: {rrl_output_dim}\", flush=True)\n",
    "\n",
    "# Hyperparameter search space\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.005, 0.01],\n",
    "    'temperature': [0.05, 0.1, 0.2],\n",
    "    'structure': [[16, 16, 8], [32, 32, 16], [64, 32, 16]]\n",
    "}\n",
    "\n",
    "best_val_f1 = -float('inf')\n",
    "best_params = None\n",
    "best_model_state = None\n",
    "best_dim_list = None\n",
    "\n",
    "print(\"Starting RRL hyperparameter search...\", flush=True)\n",
    "print(\"=\" * 60, flush=True)\n",
    "all_combos = list(product(param_grid['lr'], param_grid['temperature'], param_grid['structure']))\n",
    "print(f\"Testing {len(all_combos)} configurations\", flush=True)\n",
    "\n",
    "# Configure logging once to ensure outputs are visible\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - [%(levelname)s] - %(message)s')\n",
    "\n",
    "# Stability settings\n",
    "torch.set_num_threads(1)\n",
    "print(\"Set torch threads to 1 for stability\", flush=True)\n",
    "\n",
    "# Data Validation\n",
    "print(\"Validating data...\", flush=True)\n",
    "if np.isnan(X_rrl_train).any() or np.isinf(X_rrl_train).any():\n",
    "    print(\"WARNING: NaN or Inf found in X_rrl_train! Replacing with 0 in-place.\", flush=True)\n",
    "    np.nan_to_num(X_rrl_train, copy=False)\n",
    "\n",
    "if np.isnan(X_rrl_val).any() or np.isinf(X_rrl_val).any():\n",
    "    print(\"WARNING: NaN or Inf found in X_rrl_val! Replacing with 0 in-place.\", flush=True)\n",
    "    np.nan_to_num(X_rrl_val, copy=False)\n",
    "\n",
    "if np.isnan(X_rrl_test).any() or np.isinf(X_rrl_test).any():\n",
    "    print(\"WARNING: NaN or Inf found in X_rrl_test! Replacing with 0 in-place.\", flush=True)\n",
    "    np.nan_to_num(X_rrl_test, copy=False)\n",
    "    \n",
    "print(f\"Data shapes: Train {X_rrl_train.shape}, Val {X_rrl_val.shape}\", flush=True)\n",
    "\n",
    "for i, (lr, temp, struct) in enumerate(all_combos, start=1):\n",
    "    current_dim_list = [(discrete_flen, continuous_flen)] + list(struct) + [rrl_output_dim]\n",
    "    \n",
    "    print(f\"[{i}/{len(all_combos)}] Initializing model with lr={lr}, temp={temp}, struct={struct}\", flush=True)\n",
    "\n",
    "    try:\n",
    "        candidate_model = RRL(\n",
    "            dim_list=current_dim_list,\n",
    "            device=rrl_device,\n",
    "            use_not=True,\n",
    "            is_rank0=False, # Set to False to prevent RRL from messing with logging handlers repeatedly\n",
    "            save_best=False,\n",
    "            distributed=False,\n",
    "            use_skip=False,\n",
    "            save_path=MODELS_DIR / \"rrl_search_tmp.pth\",\n",
    "            temperature=temp\n",
    "        )\n",
    "\n",
    "        # Use fewer epochs during search for speed\n",
    "        candidate_model.train_model(\n",
    "            data_loader=rrl_train_loader,\n",
    "            valid_loader=rrl_val_loader,\n",
    "            epoch=30,\n",
    "            lr=lr,\n",
    "            weight_decay=1e-5,\n",
    "            show_progress=False\n",
    "        )\n",
    "\n",
    "        _, val_f1 = candidate_model.test(\n",
    "            test_loader=rrl_val_loader,\n",
    "            set_name='Validation',\n",
    "            show_progress=False\n",
    "        )\n",
    "\n",
    "        print(f\"[{i}/{len(all_combos)}] lr={lr}, temp={temp}, struct={struct} -> Val F1: {val_f1:.4f}\", flush=True)\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_params = {'lr': lr, 'temperature': temp, 'structure': list(struct)}\n",
    "            best_dim_list = current_dim_list\n",
    "            best_model_state = {k: v.detach().cpu() for k, v in candidate_model.net.state_dict().items()}\n",
    "\n",
    "        # Cleanup to prevent memory leaks and crashes\n",
    "        del candidate_model\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error verifying configuration {i}: {e}\", flush=True)\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Continue to next iteration if one fails\n",
    "        continue\n",
    "\n",
    "if best_model_state is None:\n",
    "    raise RuntimeError(\"Hyperparameter search did not produce a valid model.\")\n",
    "\n",
    "print(\"\" + \"=\" * 60, flush=True)\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best validation F1: {best_val_f1:.4f}\")\n",
    "print(\"=\" * 60, flush=True)\n",
    "\n",
    "rrl_model_path = MODELS_DIR / 'rrl_bank_model.pth'\n",
    "rrl_log_path = MODELS_DIR / 'rrl_bank_log.txt'\n",
    "\n",
    "# Rebuild best model and save checkpoint\n",
    "rrl_model = RRL(\n",
    "    dim_list=best_dim_list,\n",
    "    device=rrl_device,\n",
    "    use_not=True,\n",
    "    is_rank0=True,\n",
    "    distributed=False,\n",
    "    save_best=False,\n",
    "    use_skip=False,\n",
    "    temperature=best_params['temperature']\n",
    ")\n",
    "rrl_model.net.load_state_dict(best_model_state)\n",
    "rrl_model.net.eval()\n",
    "\n",
    "best_rrl_args = {\n",
    "    'dim_list': best_dim_list,\n",
    "    'use_not': True,\n",
    "    'use_skip': False,\n",
    "    'estimated_grad': False,\n",
    "    'use_nlaf': False,\n",
    "    'alpha': 0.999,\n",
    "    'beta': 8,\n",
    "    'gamma': 1,\n",
    "    'temperature': best_params['temperature']\n",
    "}\n",
    "\n",
    "torch.save({'model_state_dict': best_model_state, 'rrl_args': best_rrl_args}, rrl_model_path)\n",
    "print(f\"Saved best RRL model to {rrl_model_path}\", flush=True)\n",
    "\n",
    "# Test best model\n",
    "print(\"Testing best RRL model...\", flush=True)\n",
    "rrl_model.test(test_loader=rrl_test_loader, set_name='Test', show_progress=True)\n",
    "\n",
    "# Print Rules\n",
    "print(\"Generating rules...\", flush=True)\n",
    "rrl_rules_path = MODELS_DIR / 'rrl_bank_rules.txt'\n",
    "with open(rrl_rules_path, 'w') as f:\n",
    "    rrl_model.rule_print(db_enc.X_fname, db_enc.y_fname, rrl_train_loader, file=f, mean=db_enc.mean, std=db_enc.std)\n",
    "\n",
    "print(f\"RRL Model saved to {rrl_model_path}\", flush=True)\n",
    "print(f\"RRL Rules saved to {rrl_rules_path}\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liyf90z1f",
   "metadata": {},
   "source": [
    "### RRL Evaluation\n",
    "\n",
    "Load the trained RRL model and evaluate using the standard `evaluate_model` function for comparison with other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zmtq1ndr1cm",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm as tqdm_auto\n",
    "\n",
    "print(f\"Loading RRL model from {rrl_model_path}...\")\n",
    "\n",
    "if not rrl_model_path.exists():\n",
    "    print(f\"Error: Model file not found at {rrl_model_path}\")\n",
    "else:\n",
    "    checkpoint = torch.load(rrl_model_path, map_location=rrl_device, weights_only=False)\n",
    "    saved_args = checkpoint['rrl_args']\n",
    "    model_state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "    # Re-instantiate RRL model with saved arguments\n",
    "    rrl_eval = RRL(\n",
    "        dim_list=saved_args['dim_list'],\n",
    "        device=rrl_device,\n",
    "        use_not=saved_args['use_not'],\n",
    "        use_skip=saved_args.get('use_skip', False),\n",
    "        estimated_grad=saved_args.get('estimated_grad', False),\n",
    "        use_nlaf=saved_args.get('use_nlaf', False),\n",
    "        alpha=saved_args.get('alpha', 0.999),\n",
    "        beta=saved_args.get('beta', 8),\n",
    "        gamma=saved_args.get('gamma', 1),\n",
    "        distributed=False,\n",
    "        is_rank0=True\n",
    "    )\n",
    "\n",
    "    new_state_dict = {}\n",
    "    for k, v in model_state_dict.items():\n",
    "        name = k[7:] if k.startswith('module.') else k\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    rrl_eval.net.load_state_dict(new_state_dict)\n",
    "    rrl_eval.net.eval()\n",
    "    print(\"RRL Model loaded successfully.\")\n",
    "\n",
    "    rrl_y_proba_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm_auto(rrl_test_loader, desc=\"Generating predictions\", unit=\"batch\"):\n",
    "            X_batch = X_batch.to(rrl_device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = rrl_eval.net(X_batch)\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "            rrl_y_proba_list.extend(probs[:, 1].cpu().numpy())  # Probability of class 1 (yes)\n",
    "\n",
    "    rrl_y_proba = np.array(rrl_y_proba_list)\n",
    "\n",
    "    rrl_results = evaluate_model(\"RRL\", y_test.values, rrl_y_proba)\n",
    "    all_results.append(rrl_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
